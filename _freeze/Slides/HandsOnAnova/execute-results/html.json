{
  "hash": "89d9b25ade535c0e3c83e0c31e7d7681",
  "result": {
    "markdown": "---\ntitle: \"Hands-On ANOVA in R\"\nsubtitle: |\n   | R Coding Club \n   | RTG 2660\nauthor: \"Dr. Lea Hildebrandt\"\ndate: 2024/04/30\ndescription: \"Intro to rmANOVA and how to run ANOVAs in R\"\nformat: \n  revealjs:\n    smaller: true\n    scrollable: true\n    slide-number: true\n    theme: simple\n    embed-resources: true\neditor: visual\nfrom: markdown+emoji\n---\n\n\n# Repeated-Measures ANOVA\n\n\n::: {.cell}\n<style type=\"text/css\">\ncode.sourceCode {   font-size: 1.4em; }   \ndiv.cell-output-stdout {   font-size: 1.4em; }\n</style>\n:::\n\n\nOften in our research, we have repeated measures: We collect more than one data point from each subject.\n\nAdvantage: increased power and precision.\\\nDisadvantage: violates **iid** (independent and identically distributed) assumption of *ordinary least squares* methods (regression, ANOVA).\n\n-   independent: probability of a data point taking on specific value is independent of of values taken by other data points.\n\n-   identically distributed: data points are samples from same underlying distribution.\n\nProblem: Observations from the same subject are usually correlated (i.e. more likely to be similar to each other than to other observations).\n\n--\\> this also applies to other forms of dependency: if units of observations are clustered, e.g. mice in cage/handled by experimenter, students in classroom...\n\n. . .\n\nIn contrast to violations of other assumptions (normality, homoscadicity), ANOVA is not robust against this violation! –\\> increased type 1 error/false positives\n\n## Difference rm to \"normal\" ANOVA\n\n-   repeated measures: each subject provides several data points.\n\n-   F-statistic is calculated a bit differently: $$ F = MS_{conditions} / MS_{error} $$\n\n. . .\n\n![](images/clipboard-2385202742.png){width=\"627\"}\n\n[^1]\n\n[^1]: <https://statistics.laerd.com/statistical-guides/repeated-measures-anova-statistical-guide.php>\n\n::: notes\nMS = SS/DF\n\nSSerror decreases –\\> increased power (if compensates for reduction in DF: degrees of freedom go from (*n - k*) to (*n - 1*)(*k - 1*) )\n\nremove the variability due to the subject\n:::\n\n## Example Sum of Squares partitioning\n\nImagine, we'd have a wine tasting and everyone of you tries six different wines and gives a rating from 1-10. This way, we would get the following data set:\n\n| Subject       | Wine1     | Wine2     | Wine3 | Wine4     | Wine5     | Wine6     | Mean_subject |\n|--------|--------|--------|--------|--------|--------|----------------|--------|\n| Ecem          | 5         | 6         | 7     | 6         | 3         | 5         | **5.333**    |\n| Ulkar         | 7         | 8         | 8     | 7         | 6         | 6         | **7**        |\n| Francesco     | 1         | 4         | 3     | 7         | 4         | 4         | **3.833**    |\n| Anna          | 6         | 4         | 6     | 5         | 3         | 4         | **4.667**    |\n| Nikita        | 8         | 7         | 4     | 6         | 9         | 3         | **6.167**    |\n| Zora          | 2         | 3         | 2     | 10        | 4         | 3         | **4**        |\n| **Mean_wine** | **4.833** | **5.333** | **5** | **6.833** | **4.833** | **4.167** | **5.167**    |\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](HandsOnAnova_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n$$\nSS_{wine} = \\sum_{i=1}^{n}n_i(\\bar{x_i}-\\bar{x})^2\n$$\n\nFor every wine, we subtract the grand mean (triangle) from each wine's mean (black dots) (and multiply it by the number of subjects).\n\n$$\nSS_{within} = \\sum_{j=1}^{k}\\sum_{i=1}^{n}(x_{ij}-\\bar{x_j})^2\n$$\n\nFor the SSwithin, we subtract each individual data point from the mean of it's wine group and add that up for all wines.\n\n$$\nSS_{subjects} = k\\sum_{i=1}^{n}(\\bar{x_i}-\\bar{x})^2\n$$\n\nHere, we take *each subject's mean* and subtract the grand average from it, and multiply it with the number of wines.\n$$SS_{error} = SS_{within} - SS_{subjects}\n$$\n\nWe can then calculate the Mean Squares by dividing with the Degrees of Freedom. The MS are then used to calculate the F-Value:\n\n$$\nMS_{wine} = \\frac{SS_{wine}}{(k-1)}\n$$\n\n$$\nMS_{error} = \\frac{SS_{error}}{(n-1)(k-1)}\n$$\n\n$$F=\\frac{MS_{wine}}{MS_{error}}$$\n\n## Calculating an ANOVA in R\n\nThere are a variety of functions to run an ANOVA in R. We will be using those from the `afex` package! (But any other is fine as well! The afex package has some advantages: The contrast definition and the Type 3 sum of squares etc.)\n\nThe main function is aov_car() - because it runs the `ANOVA()` function from the `car` package. `aov_ez()` and `aov_4()` are wrappers around `aov_car()`: They should reproduce the same result, but the input format/syntax differs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(tidyverse)\nlibrary(afex)\nlibrary(performance) # for checking assumptions\nlibrary(emmeans) # for contrasts/post-hoc tests\nlibrary(report) # handy tool to help you report your findings\n```\n:::\n\n\nLet's use a bigger data set[^2]:\n\n[^2]: Example from: <https://tysonbarrett.com/jekyll/update/2018/03/14/afex_anova/> (but updated to newer packages)\n\n\n::: {.cell}\n\n:::\n\n\nWith the `afex` package, we can use the same function to calculate one-way ANOVA, factorial ANOVA, repeated measures ANOVA, and mixed ANOVA. For this aim, we always have to specify the `Error()` variance.\n\nE.g. one-way & factorial ANOVA:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type 3 tests)\n\nResponse: T_1\n     Effect     df  MSE          F  ges p.value\n1 condition 2, 297 0.90 110.38 *** .426   <.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type 3 tests)\n\nResponse: T_1\n            Effect     df  MSE          F   ges p.value\n1        condition 2, 294 0.90 108.73 ***  .425   <.001\n2           gender 1, 294 0.90       0.05 <.001    .829\n3 condition:gender 2, 294 0.90       0.78  .005    .457\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n```\n:::\n:::\n\n\n## \nRepeated measures ANOVA with afex\n\nFor a rmANOVA (in R with the afex package), we need the data to be in long format:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz_long <- z %>% \n  pivot_longer(cols = starts_with(\"T\"),\n               names_to = \"timepoint\")\n\n\n# calculate ANOVA\n\naov_rm <- z_long %>%\n  aov_car(value ~ 1 + Error(ID/timepoint),\n          data = .)\n\n# I prefer the formular notation:\naov_rm <- z_long %>%\n  aov_4(value ~ 1 + (timepoint|ID),\n        data = .)\naov_rm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type 3 tests)\n\nResponse: value\n     Effect           df  MSE    F   ges p.value\n1 timepoint 1.99, 595.97 1.06 0.28 <.001    .754\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n```\n:::\n:::\n\n\n## Mixed ANOVA\n\nWe can simply extent our model by adding between-subjects variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmixed_mod <- z_long %>%\n  aov_4(value ~ condition + gender + (timepoint|ID),\n        data = .)\nmixed_mod\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type 3 tests)\n\nResponse: value\n               Effect           df  MSE          F   ges p.value\n1           condition       2, 296 0.94 304.08 ***  .387   <.001\n2              gender       1, 296 0.94       0.32 <.001    .573\n3           timepoint 1.99, 590.22 1.06       0.28 <.001    .756\n4 condition:timepoint 3.99, 590.22 1.06       1.23  .006    .297\n5    gender:timepoint 1.99, 590.22 1.06       0.24 <.001    .786\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n```\n:::\n:::\n\n\n## Checking assumptions\n\nUnfortunately, we can't use the `performance``::check_model()` (yet) to check the assumptions of model fit with `afex`. This means that we'd have to check the assumptions individually:\n\n-   continuous DV\n\n-   (outliers)\n\n-   sphericity (the variances of the differences between all levels must be equal)\n\n-   normality of residuals\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sphericity\ntest_sphericity(mixed_mod)  # afex\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Data seems to be spherical (p > 0.641).\n```\n:::\n\n```{.r .cell-code}\ncheck_sphericity(mixed_mod) # performance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Data seems to be spherical (p > 0.641).\n```\n:::\n\n```{.r .cell-code}\n# normality of residuals\n# residuals(mixed_mod)\nplot(check_normality(mixed_mod))\n```\n\n::: {.cell-output-display}\n![](HandsOnAnova_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n## Contrasts\n\nWe can use the emmeans package to calculate \"estimated marginal means\":\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](HandsOnAnova_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\nWe can use those to calculate pairwise contrasts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|\nmixed_mod %>% \n  emmeans(specs = c(\"timepoint\", \"condition\")) %>% \n  pairs(adjust = \"tukey\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast      estimate    SE  df t.ratio p.value\n T_1 A - T_2 A  -0.0166 0.142 296  -0.117  1.0000\n T_1 A - T_3 A   0.1751 0.148 296   1.181  0.9601\n T_1 A - T_1 B   1.0370 0.134 296   7.735  <.0001\n T_1 A - T_2 B   1.0652 0.138 296   7.709  <.0001\n T_1 A - T_3 B   0.9146 0.143 296   6.382  <.0001\n T_1 A - T_1 C   1.9918 0.135 296  14.712  <.0001\n T_1 A - T_2 C   2.1386 0.139 296  15.423  <.0001\n T_1 A - T_3 C   1.9307 0.144 296  13.423  <.0001\n T_2 A - T_3 A   0.1916 0.147 296   1.307  0.9286\n T_2 A - T_1 B   1.0536 0.138 296   7.626  <.0001\n T_2 A - T_2 B   1.0818 0.142 296   7.642  <.0001\n T_2 A - T_3 B   0.9312 0.147 296   6.341  <.0001\n T_2 A - T_1 C   2.0084 0.139 296  14.491  <.0001\n T_2 A - T_2 C   2.1551 0.143 296  15.076  <.0001\n T_2 A - T_3 C   1.9473 0.147 296  13.207  <.0001\n T_3 A - T_1 B   0.8619 0.143 296   6.015  <.0001\n T_3 A - T_2 B   0.8901 0.147 296   6.061  <.0001\n T_3 A - T_3 B   0.7396 0.151 296   4.885  0.0001\n T_3 A - T_1 C   1.8168 0.144 296  12.643  <.0001\n T_3 A - T_2 C   1.9635 0.147 296  13.324  <.0001\n T_3 A - T_3 C   1.7557 0.153 296  11.484  <.0001\n T_1 B - T_2 B   0.0282 0.142 296   0.199  1.0000\n T_1 B - T_3 B  -0.1224 0.148 296  -0.825  0.9961\n T_1 B - T_1 C   0.9548 0.136 296   7.044  <.0001\n T_1 B - T_2 C   1.1016 0.139 296   7.942  <.0001\n T_1 B - T_3 C   0.8937 0.144 296   6.212  <.0001\n T_2 B - T_3 B  -0.1506 0.147 296  -1.026  0.9831\n T_2 B - T_1 C   0.9266 0.139 296   6.683  <.0001\n T_2 B - T_2 C   1.0734 0.143 296   7.500  <.0001\n T_2 B - T_3 C   0.8655 0.147 296   5.868  <.0001\n T_3 B - T_1 C   1.0772 0.144 296   7.494  <.0001\n T_3 B - T_2 C   1.2239 0.147 296   8.302  <.0001\n T_3 B - T_3 C   1.0161 0.153 296   6.639  <.0001\n T_1 C - T_2 C   0.1467 0.143 296   1.028  0.9829\n T_1 C - T_3 C  -0.0611 0.149 296  -0.409  1.0000\n T_2 C - T_3 C  -0.2078 0.148 296  -1.406  0.8948\n\nResults are averaged over the levels of: gender \nP value adjustment: tukey method for comparing a family of 9 estimates \n```\n:::\n\n```{.r .cell-code}\nmixed_mod %>% \n  emmeans(specs = trt.vs.ctrlk ~ timepoint)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$emmeans\n timepoint emmean     SE  df lower.CL upper.CL\n T_1        0.984 0.0547 296    0.876     1.09\n T_2        0.931 0.0578 296    0.817     1.04\n T_3        0.986 0.0618 296    0.865     1.11\n\nResults are averaged over the levels of: condition, gender \nConfidence level used: 0.95 \n\n$contrasts\n contrast  estimate     SE  df t.ratio p.value\n T_1 - T_3 -0.00281 0.0855 296  -0.033  0.9981\n T_2 - T_3 -0.05559 0.0845 296  -0.658  0.7262\n\nResults are averaged over the levels of: condition, gender \nP value adjustment: dunnettx method for 2 tests \n```\n:::\n:::\n\n\n## Custom Contrasts\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get emmeans\nemm1 <-  emmeans(mixed_mod, specs = ~ timepoint)\n\n# get custom contrasts from list\ncontrast(emm1, method = list(\"timepoint 1 - timepoint 2\" = T_1 - T_3) )\n# doesn't work yet\n```\n:::\n\n\n## Simple Slopes\n\n\n\n",
    "supporting": [
      "HandsOnAnova_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}